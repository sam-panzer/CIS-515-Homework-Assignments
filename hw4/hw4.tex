\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\setcounter{secnumdepth}{0}
\newcommand{\emptyspace}{\{0\}}
\newcommand{\reals}{\mathbb{R}}
\newcommand{\complex}{\mathbb{C}}
\newcommand{\trace}{\textrm{tr}}
\begin{document}

\begin{center}CIS 515 --- HW4\\Sam Panzer and Kevin Shi\end{center}
\subsection{Problem B1}
\subsubsection{(1)}
Set $m=$ argmin$_i \, |(Av)_i|$ and $n=$ argmin$_i \, |v_i|$. Assume for the sake of contradiction that we have
 \[v_n \delta > (Av)_m = \displaystyle\sum_jA_{jm}v_j\]

Now consider $(Av)_n=\displaystyle\sum_{j\neq n}A_{jn}v_j+A_{nn}v_n$. By diagonal dominance we know that the last term determines the sign of the overall sum, so thus this is minimized by
\[\displaystyle\sum_{j\neq n}A_{jn}v_j+A_{nn}v_n \ge |A_{nn}||v_n| - \displaystyle\sum_{j\neq n} |A_{jn}||v_j| = \]

Now $v_n \ge v_j \, \forall \, j$, so this becomes
\[\ge |A_{nn}||v_n| - \displaystyle\sum_{j\neq n} |A_{jn}||v_n|=|v_n|\left(|A_{nn}|-\displaystyle\sum_{j\neq n}|A_{jn}|\right)\]

But we have 
\[\delta = \min \left(|A_{ii}|-\displaystyle\sum_{j\neq i}|A_ji|\right)\]

so thus
\[|v_n|\left(|A_{nn}|-\displaystyle\sum_{j\neq n}|A_{jn}|\right) \ge |v_n|\delta > (Av)_m\]
this is a contradiction since $m$ was supposed to maximize the quantity. So $\|v\|_{\infty}\delta \le \|Av\|_{\infty}$
\subsubsection{(2)}
Suppose we had
\[\displaystyle\sup_{v\neq 0}\dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}} > \displaystyle\sup_{w\neq 0}\dfrac{\|w\|_{\infty}}{\|Aw\|_{\infty}}\]
then choose $w=A^{-1}v$ where $v$ is the maximizing argument of the LHS, so 
\[\dfrac{\|w\|_\infty}{\|Aw\|_{\infty}}=\dfrac{\|A^{-1}v\|_{\infty}}{\|AA^{-1}v\|_{\infty}}=\dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}} > \displaystyle\sup_{w\neq 0}\dfrac{\|w\|_{\infty}}{\|Aw\|_{\infty}}\]
which is clearly a contradiction. Similarly if
\[\displaystyle\sup_{v\neq 0}\dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}} < \displaystyle\sup_{w\neq 0}\dfrac{\|w\|_{\infty}}{\|Aw\|_{\infty}}\]
then choose $v=Aw$ where $w$ is the maximizing argument of the RHS to get
\[\dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}} = \dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}} > \displaystyle\sup_{v\neq 0}\dfrac{\|A^{-1}v\|_{\infty}}{\|v\|_{\infty}}\]
which is again a contradiction. So the two have to be equal.

\subsection{Problem B2}
\subsubsection{(1)}
Given $A \in GL_n$ and $||\cdot||$ a vector norm on $\complex^n$, we need to show
three properties:
\begin{itemize}
  \item For any $x \in \complex^n, ||x||_A \geq 0$ and $||x||_A = 0$ iff $x = 0$.\\
    $||x||_A = ||Ax||$, whose nonnegativity is inherited from $||\cdot||$.
    Additionally, $||Ax||$ is zero iff $Ax = 0$, and $Ax = 0$ iff $x = 0$ because $A$ is invertible.
  \item $||\lambda x||_A = |\lambda|||x||_A$, for all $x \in \complex^n, \lambda \in \complex$.\\
    $||\lambda x||_A = ||\lambda A x|| = |\lambda|||A x|| = |\lambda| ||x||_A$, since 
    $||\lambda A x|| = |\lambda|||A x||$ from $||\cdot||$.
  \item For any $x,y \in \complex^n, ||x+y||_A \leq ||x||_A + ||y||_A$.\\
    $||x+y||_A = ||A(x+y)|| = ||Ax + Ay|| \leq ||Ax|| + ||Ay|| = ||x||_A + ||y||_A$.
\end{itemize}

\subsubsection{(2)}
This time, $A \in GL_n$ and $B \in M_n$. By definition, 
$||B||_A = ||ABA^{-1}|| = \displaystyle{\sup_{x \in \complex^n, ||x|| = 1}} ||ABA^{-1}x||$
\begin{itemize}
  \item $||B||_A \geq 0$ and $||B||_A = 0$ iff $B = 0$. \\
    Nonnegativity is obvious, since we're taking the sup of the norm of vectors, and these norms must
    be nonnegative. When $B = 0, ABA^{-1}x$ is clearly $0$ for any $x$, and if $B \neq 0$,
    then $ABA^{-1}$, which has the same rank as $B$, must be nonzero.
    So at least the $x$ that is all zeros except for a 1 in a column where $ABA^{-1}$ has
    some nonzero entry will yield $||ABA^{-1}x|| > 0$, which means the sup is positive.
  \item $||\lambda B||_A = |\lambda|||B||_A$.\\
    Well, $||\lambda B||_A = ||A\lambda BA^{-1}|| = |\lambda|||ABA^{-1}|| = |\lambda|||B||_A$.
  \item For any $B, C \in M_n, ||B + C||_A \leq ||B||_A + ||C||_A$.\\
    $||B + C||_A = ||A(B + C)A^{-1}|| = ||ABA^{-1} + ACA^{-1}|| \leq ||ABA^{-1}|| + ||ACA^{-1}||
     \leq ||B||_A + ||C||_A$.
  \item And finally, $||BC||_A \leq ||B||_A||C||_A$.\\
    $||BC||_A = ||ABCA^{-1}|| = ||ABA^{-1}ACA^{-1}|| \leq ||ABA^{-1}||||ACA^{-1}|| = ||B||_A||C||_A$

\end{itemize}

\subsection{Problem B3}
\subsubsection{(1,2)} This is part of the code submission!
\subsubsection{(3,4)}
It's not hard to come up with this. We generated the matrix using exactly two vectors:
$u = (1,2,3,\dots,n)$ and $v = (1,1,\dots,1)$. Clearly, row $i$ is equal to $u + (i-1)v$.
Since $u$ and $v$ are linearly independent, $A$ has rank $2$.

In particular, this tells us that subtracting row $i$ from row $i+1$ will turn row $i+1$ into $v$.
If we do this once for each $i$ from $n-1$ to $1$, we are left with a matrix that has $u$
for its first row and $v$ for all the other rows.
Subtracting row $2$ from all rows below it therefore zeros out the matrix, giving us
\[
R = \left(
\begin{array}{ccccc}
1 & 2 & 3 & \dots & n\\
1 & 1 & 1 & \dots & 1\\
0 & 0 & 0 & \dots & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
0 & 0 & 0 & \dots & 0
\end{array}
\right)
\]
Which clearly reduces to the desired form after subtracting row 2 from row 1 (but we think this is prettier!

\subsection{Problem B4}
The characteristic polynomial of $A$ is $|\lambda I - A|$, which is equal to 
\[
\left|
\begin{array}{ccccc}
\lambda - 1 & -2 & -3 & \dots & -n\\
-2 & \lambda - 3 & -4 & \dots & -(n+1)\\
-3 & -4 & \lambda -5 & \dots & -(n+2)\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
-(n-1) & -n & -(n+1) & \dots & -2n\\
-n & -(n+1) & -(n+2) & \dots & \lambda -(2n + 1)
\end{array}
\right|
\]
Note that row $i$ is initially equal to
$(-i, -(i+1),\dots,-2i + 2, \lambda - 2i +1, -2i,\dots, -(i + n))$,
where the $i^{\text{th}}$ location has the $\lambda$.
If we consider subtracting row $i$ from row $i+1$ (with $i > 1$), then we find that row $i+1$ is.
So row $i+1$, after the subtraction, is 
$(-1, -1, \dots, -1, -\lambda -1, \lambda - 1, -1, \dots, -1)$
And now we have
\[
\left|
\begin{array}{cccccc}
\lambda - 1 & -2 & -3 & \dots & -(n-1)& -n\\
-\lambda - 1 & \lambda - 1 & -1 & \dots & -1 & -1\\
-1 & -\lambda - 1 & \lambda - 1 & \dots & -1 & -1\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
-1 & -1 & -1 & \dots & \lambda -1 & -1 \\
-1 & -1 & -1 & \dots & -\lambda - 1 & \lambda -1
\end{array}
\right|
\]

Then, we subtract row $i + 1$ from row $i$ (for $3 \leq i \leq n-1)$, to get
\[
\left|
\begin{array}{cccccccc}
\lambda - 1 & -2 & -3 & -4 & \dots & -(n-1)& -n\\
-\lambda - 1 & \lambda - 1 & & -1 -1 & \dots & -1 & -1\\
-\lambda  & 2 \lambda & \lambda & 0 & \dots & 0 & 0\\
0 & -\lambda & 2\lambda & -\lambda & \dots & 0 & 0\\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & 0 &  0 &\dots & 2\lambda  & -\lambda \\
0 & 0 & 0 & 0 & \dots & -\lambda & 2\lambda
\end{array}
\right|
\]

If we divide all rows after the first two by $\lambda$, then we find that 
$P_A(\lambda) = (-\lambda)^{n-2}P(\lambda)$, as desired.

\subsubsection{(2)}
We note that the sum of the roots of $P_A(\lambda)$ is the trace of $A$.
Since $P(\lambda) \lambda^{n-2} = P_A(\lambda)$, the sum of the roots of $P(\lambda)$ is equal to the sum of the roots of $P_A(\lambda)$, as $n-2$ of those roots are all 0.

So, we just need to compute the trace of $A$, which happens to be the sum of the first $n$ odd numbers.
Well, the sum of the first $n$ odd numbers is $n^2$, as can be seen by a quick inductive proof.  
The base case of $n=1$ is trivial. For the inductive step, we note that the $k^\textrm{th}$ odd number is $2k-1$ and consider 
$n^2 + (2(n+1)-1) = n^2 + 2n + 1 = (n+1)^2$.

Thus $\trace(P(\lambda)) = n^2$.

\medskip
The product of the roots of the characteristic polynomial of which $P(\lambda)$ is the determinant happens to be the determinant of the original matrix; this is one of the identities from class.
We can, of course, find the determinant of the original matrix by plugging $0$ into the characteristic polynomial, which gives us $\lambda_1\lambda_2 = P(0)$.

\subsubsection{(3)}
Following the suggestion, we look at the process described. First, we add
$-u_k$ times row 3 to row 1 and we add $v_k$ times row 3 to row 2.
After subtracting row 2 from row 1, we have
\begin{eqnarray*}
u_{k+1} &=&  x_k + 2u_k - v_{k+1} = x_k + 2u_k - (y_k + 2v_k)\\
x_{k+1} &=&  -3 - u_k - y_{k+1} = -3 - u_k - (-1 - v_k)\\
v_{k+1} &=&  y_k + 2v_k \\
y_{k+1} &=&  -1 - v_k
\end{eqnarray*}
which is equivalent to the expanded versoin of the desired form.

\subsubsection{(4)}
Unfolding the matrix multiplication, we have
\begin{eqnarray*}
u_{k+1} &=&  2u_k - 2v_k + x_k - y_k\\
x_{k+1} &=& -u_k + v_k - 2\\
v_{k+1} &=&  2v_k + x_k\\
y_{k+1} &=&  -v_l - 1\\
1 &=&  1
\end{eqnarray*}
which is clearly equivalent to the equations in the previous section.

Numpy (a matematical module for Python) tells me that 
\begin{verbatim}
>>> x = array([2,-2,...,0,1]).reshape(5,5)
>>> linalg.eigvals(x)
[ 1,  1,  1,  1, 1 ]
\end{verbatim}
You weren't kidding: I was surprised!

Now, if we let $N = T - I$ as described in the problem statement, nothing deep about $N$ becomes immediately apparent. It suffices to verify that $N^4 = 0$ by just squring $N$ successively!

\begin{verbatim}
>>> y = matrix(x - identity(5))
>>> y*y*y*y
matrix([0,...,0])
\end{verbatim}

The last identity follows easily by induction. The base case is trivial, as $T^0 = I$ is immediately verified when $k = 0$.
If we then assume that $T^k = I + kN + \frac{1}{2}k(k-1)N^2 + \frac{1}{6}k(k-1)(k-2)N^3$, then
\begin{eqnarray*}
  T^{k+1} &=&  TT^k = (I + N)(I + kN + \frac{1}{2}k(k-1)N^2 + \frac{1}{6}k(k-1)(k-2)N^3)\\
  &=&  I + kN + \frac{1}{2}k(k-1)N^2 + \frac{1}{6}k(k-1)(k-2)N^3 \\
  && + N + kN^2 + \frac{1}{2}k(k-1)N^3 + \frac{1}{6}k(k-1)(k-2)N^4 \\
  &=& I + (k+1)N + \frac{1}{2}(k+1)(k-1 + 2)N^2 + \frac{1}{6}(k(k-1)(k - 2 + 3))N^3 + \frac{1}{6}k(k-1)(k-2)N^4\\
  &=& I + (k+1)N + \frac{1}{2}(k+1)(k)N^2 + \frac{1}{6}(k+1)(k)(k-1) + 0
\end{eqnarray*}
as desired

\subsubsection{(5)}
The first identity is just a matter of definition, since we already have that $X_{k+1} = T X_{k}$ (where $X$ is the column vector $(u_k, v_k, x_k, y_k, 1)$) as shown in part (4).
Then it follows that left-multiplication by $T$ iterates $k$ by one, so we have $X_{k} = T^k X_0 = T^k (-1,-1,-2,-1,1)^\top$

Then, to expand $T_k$, we use the identity from $(4)$.
\[
kN = \left( 
\begin{array}{ccccc}
k & -2k & k & -k & 0 \\
0 &   k & 0 &  k & 0 \\
-k&   k & -k&  0 & 2k \\
0 &  -k & 0 & -k & -k \\
0 & 0 & 0 & 0 & 0
\end{array}
\right)
\]

\[
\frac{1}{2}k(k-1)N^2 = \left( 
\begin{array}{ccccc}
  0 & -k(k-1) & 0 & -k(k-1) & -\frac{1}{2}k(k-1) \\
  0 &   0 & 0 &  0 & -\frac{1}{2}k(k-1) \\
0 &  k(k-1) & 0 & k(k-1) & k(k-1) \\
0 &   0 & 0 &  0 &  \frac{1}{2}k(k-1)  \\
0 & 0 & 0 & 0 & 0
\end{array}
\right)
\]
And 
\[
\frac{1}{6}k(k-1)(k-2)N^3 = 
\frac{1}{2}k(k-1)N^2 = \left( 
\begin{array}{ccccc}
0 & 0 & 0 & 0 & \frac{1}{3}k(k-1) \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & -\frac{1}{3}k(k-1)  \\
0 & 0 & 0 & 0 & 0  \\
0 & 0 & 0 & 0 & 0
\end{array}
\right)
\]

So it is easily verified that 
$T^k$, the sum of the above three matrices and $I$, is as desired.

We have $X_k = T^k X_0$, so 
\begin{eqnarray*}
  u_k &=& -k+1 +k(k+1) - 2k + k^2 + \frac{1}{6}(k-1)k(2k-7)\\
  v_k &=&  -(k+1) -k - \frac{1}{2}(k-1)k\\
  x_k &=& k - k^2 -2(k-1) - (k-1)k - \frac{1}{3}k(( k-6)k + 11)\\
  y_k &=&  k - (k-1) + \frac{1}{2}(k-3)k
\end{eqnarray*}
Which again simplifies as desired.

Finally, $u_k y_k - v_k x_k$ expands to something that Wolfram Alpha tells me reduces to $-1 - \frac{7}{3}k - \frac{23}{12}k^2 - \frac{2}{3}k^3 - \frac{1}{12}k^4$ (simple polynomial algebra again omitted).

So, for $k = n -2$, we have $d_n = -1 - \frac{7}{3}(n-2) - \frac{23}{12}(n-2)^2 - \frac{2}{3}(n-2)^3 - \frac{1}{12}(n-2)^4$, which expands via computer algebra system to $P(0) = -\frac{1}{12}n^4 + \frac{1}{12} n^2$.

Thus $P(\lambda) = \lambda^2 - n^2\lambda - \frac{1}{12}n^2(n^2-1)$ once we plug in the sum and product of the roots, so $P_A(\lambda)$ has the desired form.
The two nonzero eigenvalues of $A$ can be found by the quadratic formula to be
\[\lambda =  \frac{n^2 \pm \sqrt{n^4 + 4 \frac{1}{12} n^2(n^2-1)}}{2}\]
The discriminant reduces to $n^4 + \frac{n^4}{3} - \frac{n^2}{3}$, or 
$\frac{n^2}{3}(4n^2 - 1)$, which is equivalent to the desired answer.

The phenomenon above comes from the fact that, in the last version of the negative eigenvalue shown, we have $\lambda_1 \approx -0.07735027 n^2$, since $\sqrt{1 - \frac{1}{4n^2}}$ approaches 1 once $n$ gets sufficiently large ($n = 5$ makes the square root term larger than $0.97979$).
Therefore, once we add something larget than $\lambda_1$ to each diagonal entry, we have shifted all the eigenvalues to be positive!
That is, if $l > |\lambda_1|,$ then $\det((T + lI) - \lambda' I)$ will have each roots $\lambda'_i = \lambda_i + l > 0$, since $\lambda_1$ was the most negative eigenvalue.
If all the eigenvalues are positive, then their product, the determinant, must be nonzero.

\subsection{Problem B5}
The requested plots. One which converges quickly $(<100)$ and one which converges slowly $(>1000)$.

\includegraphics[height=3in, width=5in]{15rt15.jpg}

\includegraphics[height=3in, width=5in]{1000rt1000i4.jpg}


\subsection{Extra credit (5)}
We have that
\[\epsilon_{k+1} = \frac{1}{n(\epsilon_k + 1)^{n-1} }
\left( \epsilon_k(\epsilon_k + 1)((n-1) \epsilon_k + (n-2)) + 1 - (\epsilon_k + 1)^{n-2} \right)\]
We will work without the leading factor of $\frac{1}{n(\epsilon_k + 1)}$ to simplify the algebra; also let $x = \epsilon_k$ as a shorthand. Then
\begin{eqnarray*}
&& x(x + 1)^{n-2}((n-1) x + (n-2)) + 1 - (x + 1)^{n-2}\\
&=& (x+1)^{n-2}\left( (n-1)x^2 + (n-2)x - 1 \right) + 1 \\
&=& \sum_{j=0}^{n-2}x^j \binom{n-2}{j}\left( (n-1)x^2 + (n-2)x - 1 \right) + 1 \\
&=& \sum_{j=0}^{n-2}(n-1)x^2 x^j \binom{n-2}{j} +
    \sum_{j=0}^{n-2}(n-2)x x^j \binom{n-2}{j} -
    \sum_{j=0}^{n-2}x^j \binom{n-2}{j} + 1\\
&=& \sum_{j=0}^{n-2}(n-1)x^{j+2} \binom{n-2}{j} +
    \sum_{j=0}^{n-3}(n-2)x^{j+2} \binom{n-2}{j+1} -
    \sum_{j=0}^{n-4}x^{j+2} \binom{n-2}{j+2} + 1\\
&& \textrm{Here we substituted $j=j+1$, and the $j=-1$ term is 0 so we can just include it.}\\
&=& \sum_{j=1}^{n-4}(n-1)x^{j+2} \binom{n-2}{j} + 
    (n-1)\left( x^n + x^{n-1}(n-2) + x^2 \right) +\\
    && \sum_{j=1}^{n-4}(n-2)x^{j+2} \binom{n-2}{j+1} +
    (n-2)\left( x^{n-1} + (n-2)x^2 \right) -
    \sum_{j=1}^{n-4}x^{j+2} \binom{n-2}{j+2} - \frac{1}{2}(n-2)(n-3)x^2 + 1\\
    &=& x^2(n-1)\sum_{j=1}^{n-4}x^j\frac{1}{n-1}
      \left( (n-1) \binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \right) +\\
      && (n-1)\left( x^n + x^{n-1}(n-2) + x^2 \right) + (n-2)\left( x^{n-1} + (n-2)x^2 \right) - \frac{1}{2}x^2 (n-2)(n-1) + 1\\
&&\textrm{The sum is identical to the one in $\epsilon_{k+1}$, so it remains to get $\dfrac{1}{2}n + \dfrac{n(n-2)}{n-1} x^{n-3} + x^{n-2}$}\\
&&\textrm{From Wolfram we get}\\
&&(n-1)\left( x^n + x^{n-1}(n-2) + x^2 \right) + (n-2)\left( x^{n-1} + (n-2)x^2 \right) - \frac{1}{2}x^2 (n-2)(n-1)\\
&=& \dfrac{1}{2}(n^2 (2x^{n-1} + x^2) - 2(x^n -1) + n(-4x^{n-1} + 2x^n - x^2))\\
&&\textrm{We factor $(n-1)x^2$ out of it to get}\\
	&=& x^2(n-1) \left( \dfrac{1}{2}n + x^{n-2} + \dfrac{(n-2)n x^{n-3}}{n-1} \right)\\
&&\textrm{So putting all this together we get}\\
&&\epsilon_{k+1} = \dfrac{1}{n(\epsilon_k+1)^{n-1}} \epsilon_k^2(n-1)\sum_{j=1}^{n-4}\epsilon_k^j\frac{1}{n-1}
      \left( (n-1) \binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \right)+ \\ 
&&\dfrac{1}{n(\epsilon_k+1)^{n-1}} \epsilon_k^2(n-1) \left( \dfrac{1}{2}n + \epsilon_k^{n-2} + \dfrac{(n-2)n \epsilon_k^{n-3}}{n-1} \right)\\
&=& \dfrac{(n-1)}{n} \dfrac{\epsilon_k^2 \mu_n (\epsilon_k)}{(\epsilon_k+1)^{n-1}}\\
\end{eqnarray*}
as desired.
\vspace{1cm}

To show that the two expressions for $\mu_n(a)$ are equal, we only need to show that 
\[ \sum_{j=1}^{n-4} a^j \frac{1}{n-1}\left( (n-1)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \right) =
\frac{n(n-2)}{3}a + \sum_{j=2}^{n-4}\frac{j+1}{j+2}\frac{n}{n-1}a^j \binom{n-1}{j+1} 
\]
First, we'll pull off the $j = 1$ term on the left, and show it's equal to the part not included in the summation on the right.
When $j=1$, we have
\begin{eqnarray*}
& & a\frac{1}{n-1}\left( (n-1)\binom{n-2}{1} + (n-2)\binom{n-2}{2} - \binom{n-2}{3} \right) \\
&=&  a\frac{1}{n-1}\left( (n-1)(n-2) + \frac{1}{2}(n-2)(n-2)(n-3) - \frac{1}{6}(n-2)(n-3)(n-4) \right) \\
&=&  a\frac{n-2}{6(n-1)}\left(6(n-1) + 3(n-2)(n-3) - (n-3)(n-4) \right) \\
&=&  a\frac{n-2}{6(n-1)}(2n^2 - 2) =  a\frac{2n(n-1)(n-2)}{6(n-1)} \\
&=&  a\frac{n(n-2)}{3}
\end{eqnarray*}
This leaves the rest of the first summation, but with $j$ starting at $2$. Our goal becomes to show that
\[
\sum_{j=2}^{n-4} a^j \frac{1}{n-1}\left( (n-1)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \right) 
 = \frac{n(n-2)}{3}a + \sum_{j=2}^{n-4}\frac{j+1}{j+2}\frac{n}{n-1}a^j \binom{n-1}{j+1} 
\]
Note that both summations have a common $\frac{a^j}{n-1}$ term, further reducing the problem to showing that
\[
\sum_{j=2}^{n-4} \left( (n-1)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \right) 
 = \sum_{j=2}^{n-4}\frac{j+1}{j+2}n \binom{n-1}{j+1} 
\]
Now, we can compare the two summations term-by-term. Let's transform the left side of this equation.
\begin{eqnarray*}
& & (n-1)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \\
&=& (n-2 + 1)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \\
&=& \binom{n-2}{j} + (n-2)\binom{n-2}{j} + (n-2)\binom{n-2}{j+1} - \binom{n-2}{j+2} \\
&=& (n-2)\left(\binom{n-2}{j} + \binom{n-2}{j+1}\right) + \binom{n-2}{j} - \binom{n-2}{j+2} \\
&=& (n-2)\binom{n-1}{j + 1} + \binom{n-2}{j} - \binom{n-2}{j+2} \\
&=& (n-2)\binom{n-1}{j + 1} + \left( \binom{n-2}{j} + \binom{n-2}{j+1}  \right)-
\left( \binom{n-2}{j+1} - \binom{n-2}{j+2}  \right)\\
&=& (n-2)\binom{n-1}{j + 1} + \binom{n-1}{j+1} - \binom{n-1}{j+2}\\
&=& (n-1)\binom{n-1}{j + 1} - \binom{n-1}{j+2}\\
&=& (n-1)\binom{n-1}{j + 1} - \frac{(n-1)!}{(j+2)!(n-(j+3))!}\\
&=& (n-1)\binom{n-1}{j + 1} - \frac{(n-1)!(n-(j+2))}{(j+2)(j+1)!(n-(j+2))(n-(j+3))!}\\
&=& (n-1)\binom{n-1}{j + 1} - \frac{(n-(j+2))}{(j+2)}\frac{(n-1)!}{(j+1)!(n-(j+2))!}\\
&=& (n-1)\binom{n-1}{j + 1} - \frac{(n-(j+2))}{(j+2)}\binom{n-1}{j+1}\\
&=& \left( (n-1)- \frac{(n-(j+2))}{(j+2)} \right)\binom{n-1}{j+1}\\
&=& \left( (n-1)- \left(\frac{n}{j+2} - 1\right) \right)\binom{n-1}{j+1}\\
&=& \left( n- \frac{n}{j+2} \right)\binom{n-1}{j+1}\\
&=& n\left(1 - \frac{1}{j+2} \right)\binom{n-1}{j+1}\\
&=& n\frac{j+1}{j+2} \binom{n-1}{j+1}\\
\end{eqnarray*}
Whew! The two descriptions of $\mu_n(a)$ are equivalent.
\newpage
\subsection{(6)}
For $j\ge 1$, the coefficient of $a^j$ in $a\mu_n$ corresponds to the coefficient $a^{j+1}$ in $\mu_n$, which occurs in the summation. So this coefficient is \[\dfrac{(j)n}{(j+1)(n-1)} \dbinom{n-1}{j}\] 

The coefficient of $a^j$ in $(a+1)^{n-1}-1$ is 
\[\dbinom{n-1}{j}\]

For $n> j$ we have 
\[jn \le jn + n - j - 1 = (n-1)(j+1) \Longrightarrow \dfrac{j}{j+1} \le \dfrac{n-1}{n} \Longrightarrow \dfrac{jn}{(j+1)(n-1)} \le 1\]

Thus
\[\dfrac{(j)n}{(j+1)(n-1)} \dbinom{n-1}{j} \le \dbinom{n-1}{j}\]

We see that the inequality is strict if $n-j>1$ since then $n-j-1>0$, so for $n\ge 3$ and $j\le n-2$, the inequality is strict. 

For the last statement, we have
\[\eta_{n,k+1} = \mu_n(\epsilon_1) \left(\dfrac{n-1}{n}\right) \dfrac{\epsilon_k^2 \mu_n (\epsilon_k)}{(\epsilon_k +1)^{n-1}} =  \left(\dfrac{n-1}{n}\right) \eta_{n,k}^2 \dfrac{\mu_n(\epsilon_k)}{\mu_n(\epsilon_1)} \dfrac{1}{(\epsilon_k+1)^{n-1}}\]

Now $\epsilon_1 \ge \epsilon_k$ so $\dfrac{\mu_n(\epsilon_k)}{\mu_n(\epsilon_1)} \le 1$, and also $(1+\epsilon_k)>1$ so $\dfrac{1}{(\epsilon_k+1)^{n-1}} \le 1$. Thus we get
\[\eta_{n,k+1} \le \left(\dfrac{n-1}{n}\right) \eta_{n,k}^2\]

\end{document}
