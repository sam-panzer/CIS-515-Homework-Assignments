\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath}

\setcounter{secnumdepth}{0}
\newcommand{\emptyspace}{\{0\}}
\begin{document}

\begin{center}CIS 515 --- HW2\\Sam Panzer and Kevin Shi\end{center}
\subsection{Problem B1}
We'll do this by induction on $n$.
The base case is trivial, since then $AB := A_1(B_1^\top)^\top$.

For the inductive step, we assume that $n >= 1$, and we let $A'$ be the first
$n - 1$ columns of $A$ and $B'$ be the first $n - 1$ rows of $B$. Furthermore,
let $a$ be the last column of $A$ and $b$ be the last column of $B$.
Our induction hypothesis is that
$A'B' = A_1(B_1'^\top)^\top + \dots + A_{n-1}(B_{n-1}'^\top)^\top $.
Note that
\[(AB)_{i,j} = \left( \sum_{k=1}^{n-1} A_{i,k}B_{k,j} \right) + a_ib_j
             = (A'B')_{i,j} + a_ib_j\]
Because the sum is just $A'B'$, we can break this up to be
\[AB = A'B' + ab = A_1(B_1'^\top)^\top + \dots + A_{n-1}(B_{n-1}'^\top)^\top  +
ab\]
Since $ab$ is defined to be $A_n(B_n^\top)^\top$, we just cite the induction
hypothesis to conclude the proof.

\subsection{Problem B2}
$f: E \rightarrow F$ is a bijective lineasr map. To show that $f^{-1}$ is
linear, note that $f^{-1} \circ f = id$ and consider
\begin{eqnarray*}
f^{-1}(a) + f^{-1}(b) &=& id(f^{-1}(a) + f^{-1}(b) )\\
&=& f^{-1}(f(f^{-1}(a) + f^{-1}(b))) \\
&=&f^{-1}(f(f^{-1}(a)) + f(f^{-1}(b)))\\
&=& f^{-1}(a + b)
\end{eqnarray*}
\subsection{Problem B3}
\subsubsection{(1)}
This proof requires two directions.
First, let's assume that $z = (u_1,\dots,u_{i-1},v,u_{i+1}, \dots, u_p) \in Z_i$
for some $i$.
This means that 
\[a(z) = \sum_{j = 1, j \neq i}^p u_j + v 
      = \sum_{j = 1, j \neq i}^p u_j - \sum_{j = 1, j \neq i}^p u_j = 0\]
Thus $a(z) = 0$ for each $z$ in any $Z_i$. $a$'s linearity therefore implies
that any linear combination of vectors drawn from the $Z_i$ is therefore in its
kernel, which means that $\ker(a) \supseteq Z_1 + \dots + Z_p$.

For the other direction, we assume that $u = (u_1,\dots,u_p) \in \ker(a)$.
Then $u_i = -\sum_{j = 1, j \neq i} u_j$ for each $i$, since $a(u) = 0$ implies
that $u_1 + \dots + u_p = 0$.
This means that $u$ satisfies the criterion for membership in any $Z_i$, so it
must be a member of $Z_ + \dots + Z_p$.
Therefore $Z_ + \dots + Z_p \supseteq \ker(a)$, meaning that the two spaces are
equivalent.

\subsubsection{(2)}
The sum is a direct sum iff $a$ is injective.
First, let's assume that $a$ is in fact injective, which means that, for
$u_i,v_i \in U_i$,
$u_1 + \dots + u_p = v_1 + \dots + v_p$ iff $u_i = p_i \forall i$.
We need to show that
\[V_i = U_i \cap \left( \sum_{j=1,j\neq i}^p U_j \right)\]
is the trivial vector space for each $i$. We suppose that $x \in V,$ which means that
$x = u_i \in U_i$ and $x = \displaystyle{\sum_{j=1,j \neq i}^p} u_j$ where
$u_j \in U_j$.
Then we have $0 = u_i - \displaystyle{\sum_{j=1,j \neq i}^p} u_j$, and we can
look at this equation as comparing the values of $a$ applied to to $(0,\dots,0)$
and $(u_1,\dots,u_p)$. Therefore $a$'s injectivity implies that $(u_1,\dots,u_p)
= 0$, so we conclude that $x = 0$, as desired.

\medskip
For the other direction, we assume that if $x \in U_i$ and $x =
\displaystyle{\sum_{j=1,j \neq i}^p} u_j$ then $x = 0$.
If we then let $a(u_1,\dots,u_p) = a(v_1,\dots,v_p)$ with $u_j \in U_j$, then we
have $u_1 + \dots + u_p = v_1 + \dots + v_p$. In fact, for any $i$, this can
become $(u_i - v_i) = \displaystyle{\sum_{j=1,j \neq i}^p} v_j - u_j$. But then
we expressed an element of $U_i$ as the sum of one element from each other $U_j$
(since $u_k, v_k \in U_k$ for all $k$, their difference is in $U_k$), which
allows us to apply our assumption that such an element is 0.
Thus $(u_1,\dots,u_p) - (v_1,\dots,v_p) = 0$, which implies that the two vectors
are equal; $a$ must therefore be injective, as desired.

\subsubsection{(3)}
Given $f_1 + \dots + f_p = id$, we can compose any $f_i$ on the left of this to
obtain, by linearity, $f_i \circ f_1 + \dots + f_i \circ f_p = f_i$, or
\[f_i^2 + \sum_{j=1,j \neq i}^p f_i \circ f_j = f_i, \forall\, i\]

If we now assume that $f_i \circ f_j = 0$ when $i \neq j$, we immediately have
that $f_i^2 = f_i, \forall\, i$, since each term in the summaitois just 0.

The other direction is a little trickier. Let's assume that $f_i^2  = f_i,
\forall\, i$
Starting with the summation from above, we have
\[\sum_{j=1,j \neq i}^p f_i \circ f_j = 0 \]

\subsection{Problem B4}
$f \circ f = f$

\subsection{Problem B5}
\subsection{Problem B6}
\subsubsection{(a)}
\[
E=\left( 
\begin{array}{cccc}
1 &0 &0 &0\\
-1&1 &0 &0\\
0 &-1&1 &0\\
0 &0 &-1&1\\
\end{array}
\right)
\]
This works, since all we needed to do was subtract each row from the following
row.
\subsubsection{(b)}
This product subtracts row 4 from row 3, then row 3 from row 2, then row 2 from
row 1, followed by subtracting row 4 from row 3 again, then row 3 is subtracted
from row 2, and finally row 4 is subtracted from row 3 \emph{again}.
In other words, it ends up tunring the Pascal matrix into the identity!
\subsubsection{(c)}
Very funny. It's the product above, which is 
\[
E=\left( 
\begin{array}{cccc}
1 &0 &0 &0\\
-1&1 &0 &0\\
1 &2 &1 &0\\
-1&3 &-3&1\\
\end{array}
\right)
\]

\subsubsection{(d)}
As we're trying to go from the first $n$ rows of Pascal's triangle to $n-1$ rows
of it, all we need to do is subtract row $i$ from row $i+1$ from bottom to top.
This takes the form of
$E_{2,1;-1}E_{3,2;-1}\dots E_{n,(n-1); -1}E_{(n+1),n; -1}$.


\end{document}
